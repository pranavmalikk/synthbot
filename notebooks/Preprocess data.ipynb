{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You do not need to do any of this\n",
    "This file walks you through the preprocessing steps for:\n",
    "1. Cleaning the data,\n",
    "2. Aligning transcripts to utterances at the phoneme level, and\n",
    "3. Packaging the data for data science and machine learning uses.\n",
    "\n",
    "**This is a slow, painful, and iterative process. If you're just interested in data science / machine learning, I recommend skipping this and downloading the end results.**\n",
    "\n",
    "If you want to help out with programmatic data cleaning, then this is for you. There's a lot of work to be done here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert clipper-formatted data to mfa-formatted data\n",
    "The goal here is to run Montreal Forced Aligner (MFA) through Clipper's clips. Clipper's files are flac files and word-level transcripts. MFA takes in 16khz wave files and word-level transcripts, and it outputs phoneme-level transcripts. The `datapipes` module in `src/` can convert Clipper's files into MFA-compatible input.\n",
    "\n",
    "First step: do a dry-run to check for any errors in the Clipper files we have. Sometimes there's a filename mismatch, a missing character name, missing transcript file, or similar. While running this, you'll see the `In [ ]` on the left-hand side change to `In [*]`. When it's complete, you'll see it change to `In [1]`. The number `[1]` tells you the order in which commands on this page were executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!(cd ../src; python -m datapipes --mfa-inputs \\\n",
    "    --input /home/celestia/data/clipper-samples `# clipper-formatted directory` \\\n",
    "    --output /home/celestia/data/mfa-inputs `# mfa-formatted directory` \\\n",
    "    --delta `# ignore files already processed` \\\n",
    "    --dry-run `# don't create any output files`) | nl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are any errors, make sure to fix them and re-run the above command. Repeat until there are no errors, then run the next command to generate the mfa-formatted data. If you're running this on all of Clipper's data, this might take an hour to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!(cd ../src; python -m datapipes --mfa-inputs \\\n",
    "    --input \"/home/celestia/data/clipper-samples\" \\\n",
    "    --output /home/celestia/data/mfa-inputs \\\n",
    "    --delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run montreal-forced-aligner with the following command to generate phoneme-level transcripts. Note that, due to quirks with IPython, this command won't produce intermediate output, so you won't be able to monitor progress here. If you're running this on all of Clipper's data, this command might take a few hours to complete. You can monitor progress by watching the `data/mfa-alignments` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "rm -r /home/celestia/data/mfa-alignments\n",
    "rm -r /home/celestia/Documents/MFA\n",
    "\n",
    "function mfa() {\n",
    "    mkdir /home/celestia/data/mfa-alignments/$1 || true\n",
    "    yes n | mfa_align -v `# continue even with an incomplete dictionary` \\\n",
    "        /home/celestia/data/mfa-inputs/$1 `# input directory` \\\n",
    "        /opt/mfa/pronunciations_dicts/english.dict.txt \\\n",
    "        /opt/mfa/pretrained_models/english.zip \\\n",
    "        /home/celestia/data/mfa-alignments/$1 `# output directory` \\\n",
    "        || true\n",
    "}\n",
    "\n",
    "export -f mfa\n",
    "\n",
    "ls /home/celestia/data/mfa-inputs | xargs -L1 -P16 bash -c 'mfa $@' _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's extremely likely that MFA failed on some inputs. There are three ways in which it can fail:\n",
    "1. MFA found a word it didn't recognize and logged both the missing word and corresponding utterance.\n",
    "2. MFA failed in some unexpected way while doing preprocessing for a character, and it borked its own configuration files.\n",
    "3. MFA couldn't figure out how to align the transcript to an utterance.\n",
    "\n",
    "For the first kind of failure, you can find an `oovs_found.txt` file in each of the directories within `mfa-alignments`. This file contains a list of words that could not be processed because they don't exist in the pronunciation dictionary. You can find the current pronunciation dictionary in `/opt/mfa/pronunciations_dicts/english.dict.txt`. If you end up adding the pronunciations of any missing words, make sure to post them to the thread. I can update the Docker image so everyone can benefit from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat /home/celestia/data/mfa-alignments/*/oovs_found.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second and third kinds of failure, you can find out which characters MFA failed to process by searching for the empty directories  in `mfa-alignments`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! find /home/celestia/data/mfa-alignments -type d -empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above command produces any output, it's very likely that MFA stochastically borked something during its own preprocessing stage. The easiest way to handle this is to remove its character-specific cache directory and try again.\n",
    "\n",
    "The following script does exactly that for the case where MFA fails on Applejack's files. In my case, I needed to run this for Apple-Bloom, Applejack, Cadance, and Rainbow-Dash the most recent time, but MFA's failures are pretty stochastic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "retry_character=\"AK-Yearling\"\n",
    "\n",
    "rm -r \"/home/celestia/Documents/MFA/$retry_character\"\n",
    "\n",
    "yes n | mfa_align -v \\\n",
    "        /home/celestia/data/mfa-inputs/$retry_character \\\n",
    "        /opt/mfa/pronunciations_dicts/english.dict.txt \\\n",
    "        /opt/mfa/pretrained_models/english.zip \\\n",
    "        /home/celestia/data/mfa-alignments/$retry_character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last type of MFA failure is the only one that's complicated to handle. If you run the following command, you can see a list of transcripts that MFA failed to align."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "function get_textgrids() {\n",
    "    (cd \"$1\"\n",
    "    find -iname '*.textgrid' |\n",
    "        sed 's/\\.textgrid$//gI' |\n",
    "        sort)\n",
    "}\n",
    "\n",
    "diff <(get_textgrids /home/celestia/data/mfa-inputs) <(get_textgrids /home/celestia/data/mfa-alignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you didn't complete the above steps for handling whole-character issues, you'll notice that some characters have a huge number of utterances listed. If you did complete the above steps, none of the characters should have _that_ many failures. For me, the worst offender is Pinkie Pie with 77 failures, followed by Fluttershy and Twilight Sparkle both with around 35. If a character has a huge number of utterances listed, it's likely that MFA crashed at some point. You can read through its logs in `/home/celestia/Documents/MFA/` to try to figure out why. \n",
    "\n",
    "You can try playing some of the listed files to figure out why MFA might be failing on them. I've found that it's often because either (1) the character is speaking in a very excited or abnormal way, (2) the clip is noisy or muffled, or (3) the utterance contains a lot of out-of-dictionary words.\n",
    "\n",
    "Eventually, we'll want to find a way to make use of these utterances to generate more realistic speech in niche cases, but for now we can ignore them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packaging data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading utterances from  /home/celestia/data/clipper-samples\n",
      "reading transcipts and labels from labels.text files\n",
      "writing output files to /home/celestia/data/audio-tar\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "!(cd ../src; python -m datapipes --audio-tar \\\n",
    "    --input-audio /home/celestia/data/clipper-samples `# clipper-formatted directory` \\\n",
    "    --input-alignments /home/celestia/data/mfa-alignments `# mfa-formatted directory` \\\n",
    "    --output /home/celestia/data/audio-tar `# output per-character tar.gz files here` \\\n",
    "    --audio-format 'wav' \\\n",
    "    --sampling-rate 48000 \\\n",
    "    --dry-run `# don't create any output files` \\\n",
    "    --verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading utterances from  /home/celestia/data/clipper-samples\n",
      "reading transcipts and labels from labels.text files\n",
      "writing output files to /home/celestia/data/audio-tar\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "!(cd ../src; python -m datapipes --audio-tar \\\n",
    "    --input-audio /home/celestia/data/clipper-samples \\\n",
    "    --input-alignments /home/celestia/data/mfa-alignments \\\n",
    "    --output /home/celestia/data/audio-tar \\\n",
    "    --audio-format 'wav' \\\n",
    "    --sampling-rate 48000 \\\n",
    "    --verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the archives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is interrupted.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "function generate_info() {\n",
    "    source=\"$(readlink -f $1)\"\n",
    "    target=\"/home/celestia/data/audio-info/$(basename $source .tar).txz\"\n",
    "    (cd ../src; python -m datapipes --audio-info \\\n",
    "        --input-tar \"$source\" \\\n",
    "        --output-txz \"$target\" \\\n",
    "        --verbose) || true\n",
    "}\n",
    "\n",
    "export -f generate_info\n",
    "\n",
    "ls /home/celestia/data/audio-tar/* | xargs -L1 -P16 bash -c 'generate_info $@' _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "function generate_tfrecords() {\n",
    "    audio=\"$(readlink -f $1)\"\n",
    "    info=\"/home/celestia/data/audio-info/$(basename $audio .tar).txz\"\n",
    "    tfrecord=\"/home/celestia/data/audio-tfrecord/$(basename $audio .tar).tfrecord\"\n",
    "    (cd ../src; python -m datapipes --audio-record \\\n",
    "        --input-audio \"$audio\" \\\n",
    "        --input-info \"$info\" \\\n",
    "        --output-tfrecord \"$tfrecord\" \\\n",
    "        --verbose) || true\n",
    "}\n",
    "\n",
    "export -f generate_tfrecords\n",
    "\n",
    "ls /home/celestia/data/audio-tar/* | xargs -L1 -P16 bash -c 'generate_tfrecords $@' _"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
