{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the speech corpus\n",
    "\n",
    "Before going through this, make sure you've gone through `notebooks/Preprocess data.ipynb` first.\n",
    "\n",
    "This file will walk you through the main synthbot components for working with utterances. The goal here is to generate a 'hello world' utterance using clips of Twilight's speaking. This requires:\n",
    "1. Loading Twilight's speech corpus,\n",
    "2. Finding relevant sound clips, and\n",
    "3. Piecing them together into a single utterance.\n",
    "\n",
    "Let's start by running the tests to make sure we have a working installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!../run-tests.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a red bar on the bottom stating that you've failed some tests, something's wrong. If you have a green bar stating the number of tests that passed, you're good to go.\n",
    "\n",
    "Import the relevant files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "import IPython.display as ipd\n",
    "from ponysynth.soundsheaf import *\n",
    "from ponysynth.speechcorpus import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walking through the imports:\n",
    "* Everything in this notebook is running in an IPython interpretor. The `sys.path.append('../src')` tells IPython where to find the `ponysynth` module. We're currently in `synthbot/notebooks`, and we need to add `synthbot/src` to the python path.\n",
    "* We'll be using `IPython.display` to play the audio we generate.\n",
    "* `ponysynth.soundsheaf` contains the basic sound data structures that `ponysynth` uses. It also contains utility functions to work with `SoundSheaf`s, including one to piece together audio.\n",
    "* `ponysynth.speechcorpus` contains the basic corpus management data structures and utility functions.\n",
    "\n",
    "We'll be using `load_character_corpus` from `ponysynth.speechcorpus` to load audio and phoneme-level transcripts for Twilight. These are the same phoneme-level transcripts that we generated in `notebooks/Preprocess data.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twilight = load_character_corpus(\n",
    "    audio_folder='/home/celestia/data/mfa-inputs/Twilight-Sparkle',\n",
    "    transcripts_folder='/home/celestia/data/mfa-alignments/Twilight-Sparkle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`load_character_corpus` returns an object of type `SpeechCorpus`. Right now, the only thing `SpeechCorpus` does is index audio files so phones (sound associated with phonemes) are easy to find. We can use that to find utterances that sound like parts of \"hello world\". Note that to find the phonemes for \"hello world\", I went through the pronunciation dictionary mentioned in `notebooks/Preprocess data.ipynb`.\n",
    "\n",
    "The following will find a set of phones and diphones sufficient to say \"hello world\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_phonemes = ['HH', 'EH0', 'L', 'OW1', 'W', 'ER1', 'L', 'D']\n",
    "target_diphonemes = list(zip(target_phonemes[:-1], target_phonemes[1:]))\n",
    "\n",
    "available_diphones = [twilight.find_utterances(x) for x in target_diphonemes]\n",
    "diphone_selections = [next(x, None).diphone_sequence for x in available_diphones]\n",
    "\n",
    "available_pre = twilight.find_utterances(['HH'])\n",
    "pre_selection = next(available_pre, None)\n",
    "\n",
    "available_post = twilight.find_utterances(['D'])\n",
    "post_selection = next(available_post, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a list of utterances, each of which contains one part of \"hello world\". The following will merge these utterances together into a single \"sound\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chained_diphones = reduce(merge_diphseq, diphone_selections)\n",
    "hello_utterance = merge_utterances(pre_selection, chained_diphones, post_selection)\n",
    "hello_soundsheaf = hello_utterance.get_sheaf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A note on terminology: a sheaf is spatial (or termporal) data. A \"soundsheaf\" deals specifically with temporal PCM (frame) data. A soundsheaf is defined by (1) a time interval, and (2) an assignment of PCM data to each point in that time interval. I'm using the word \"soundsheaf\" because the word \"sound\" is ambiguous. Sometimes \"sound\" refers to PCM data, sometimes it refers to frequencies, and sometimes it refers to a soundsheaf.\n",
    "\n",
    "An utterance is a soundsheaf with content (e.g., words, phonemes). Each constituent soundsheaf in `hello_soundsheaf` contains at least one phone or diphone of content. When we merge soundsheaves with `merge_diphseq` and `merge_utterances`, we're hoping that the result sounds like natural, but it might not. The reason is that, in natural speech, adjacent sounds need to abide by some rules (e.g., they should be spoken in similar voices), and our naive `merge_*` implementations might break those rules.\n",
    "\n",
    "One of our eventual goals will be to adjust the merged soundsheaves during the merging process so those rules don't get broken. For now, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(hello_soundsheaf.get_image(), rate=16000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
