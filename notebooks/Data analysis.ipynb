{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ponysynth.models.label_embeddings import *\n",
    "\n",
    "# if we have excess gpu memory and compute, virtualize the gpu to increase the batch size\n",
    "# if we have excess gpu compute, run multiple steps per batch\n",
    "\n",
    "# treat gradient descent as a beam search\n",
    "# if we have excess gpu memory, increase the beam size\n",
    "# if we have excess gpu compute, increase the beam depth\n",
    "\n",
    "archive_fn = '/home/celestia/data/audio-tfrecord/*'\n",
    "\n",
    "# strategy = tf.distribute.OneDeviceStrategy(device='/gpu:0')\n",
    "#strategy = tf.distribute.MirroredStrategy()\n",
    "gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "strategy = snt.distribute.Replicator(\n",
    "    [f\"/device:GPU:{i}\" for i in range(len(gpus))],\n",
    "    tf.distribute.ReductionToOneDevice(\"GPU:0\")\n",
    ")\n",
    "print(f'using {len(gpus)} gpus')\n",
    "\n",
    "replica_batch_size = 64\n",
    "global_batch_size = replica_batch_size * len(gpus)\n",
    "\n",
    "\n",
    "dataset = input_db(archive_fn, global_batch_size)\n",
    "dataset = strategy.experimental_distribute_dataset(dataset)\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    opt = snt.optimizers.Adam(learning_rate=0.0004)\n",
    "    model = VAEModel(SimpleVAE(30))\n",
    "    \n",
    "    def train_step(ids, weights):\n",
    "        features = tf.sparse.to_dense(weights)\n",
    "        features.set_shape((replica_batch_size, index_end - index_start))\n",
    "        loss, grads, params = model.gradients(features)\n",
    "        opt.apply(grads, params)\n",
    "        return loss\n",
    "        \n",
    "    @tf.function\n",
    "    def distributed_train_step(ids, weights):    \n",
    "        losses = strategy.experimental_run_v2(train_step, args=(ids, weights))\n",
    "        return strategy.reduce(tf.distribute.ReduceOp.SUM, losses, axis=None) / global_batch_size\n",
    "        \n",
    "    for ids, weights in dataset:\n",
    "        loss = distributed_train_step(ids, weights)\n",
    "        print(loss)\n",
    "\n",
    "# todo: test this with tpus\n",
    "# todo: add loss mask for unknown values\n",
    "# todo: train with bert-like mask\n",
    "# todo: figure out what structure to use... convolution?\n",
    "# todo: figure out how to generate embeddings\n",
    "# todo: create a encoding -> 2d differential net for speech\n",
    "# todo: write custom optimizer for metalearning\n",
    "# THEN improve with xlnet, al-bert, etc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Burnt-Oak-outtakes:s7e13-2266.283789-2268.209568\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 414 but corresponding boolean dimension is 233",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-178-ce305c8f72e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Burnt-Oak-outtakes:s7e13-2266.283789-2268.209568'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mclean_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_faded_trim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0munclean_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marchive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0munclean_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munclean_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-178-ce305c8f72e5>\u001b[0m in \u001b[0;36mapply_faded_trim\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mclipbot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClipBot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_cutoff_times\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-178-ce305c8f72e5>\u001b[0m in \u001b[0;36mfind_cutoff_times\u001b[0;34m(label, info)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#     return label['words'][0]['interval'][0], label['words'][-1]['interval'][-1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mintensities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'intensity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'volume.db'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mintensities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mintensities\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-178-ce305c8f72e5>\u001b[0m in \u001b[0;36mthreshold\u001b[0;34m(intensities)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mreference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmedian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mreference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintensity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mintensities\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreference\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 414 but corresponding boolean dimension is 233"
     ]
    }
   ],
   "source": [
    "from ponysynth.corpus import *\n",
    "from ponysynth.clipbot import ClipBot\n",
    "from datapipes.audiorecord_out import *\n",
    "from IPython import display as ipd\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "archive = ClipperArchive('/home/celestia/data/clipper-preproc/audio-tar/Burnt-Oak.tar')\n",
    "extra = InfoArchive('/home/celestia/data/clipper-preproc/audio-info/Burnt-Oak.txz')\n",
    "\n",
    "def find_cutoff_times(label, info):\n",
    "#     return label['words'][0]['interval'][0], label['words'][-1]['interval'][-1]\n",
    "    intensities = [x for x in info['intensity']]\n",
    "    th = threshold([float(x['volume.db']) for x in intensities])\n",
    "    \n",
    "    for start in intensities:\n",
    "        if float(start['volume.db']) >= th:\n",
    "            break\n",
    "    \n",
    "    for end in intensities[::-1]:\n",
    "        if float(end['volume.db']) >= th:\n",
    "            break\n",
    "    \n",
    "    return float(start['time.sec']), float(end['time.sec'])\n",
    "\n",
    "\n",
    "def fade(indexes):\n",
    "    return indexes * 0\n",
    "\n",
    "def threshold(intensities):\n",
    "    mean = np.mean(intensities)\n",
    "    median = np.median(intensities)\n",
    "    reference = None\n",
    "\n",
    "    if median > mean:\n",
    "        reference = median\n",
    "    else:\n",
    "        reference = np.median(intensity[intensities > mean])\n",
    "\n",
    "    return reference - 13\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def apply_faded_trim(key):\n",
    "    audio = archive.read_audio(key)\n",
    "    samples, rate = librosa.core.load(audio, sr=None)\n",
    "    label = archive.read_label(key)\n",
    "    info = extra.read_info(key)\n",
    "    \n",
    "    clipbot = ClipBot(samples, rate)\n",
    "    start_time, end_time = find_cutoff_times(label, info)\n",
    "    print(start_time, end_time)\n",
    "    \n",
    "    start, mid, end = clipbot.split(start_time, end_time)\n",
    "    start.mod.crossfade(pre=fade)\n",
    "    end.mod.crossfade(post=fade)\n",
    "    \n",
    "    return clipbot.get_samples(), rate\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#for key in archive.sample(k=10):\n",
    "for key in ('Burnt-Oak-outtakes:s7e13-2266.283789-2268.209568',):\n",
    "    print(key)\n",
    "    clean_samples, rate = apply_faded_trim(key)    \n",
    "    unclean_file = archive.read_audio(key)\n",
    "    unclean_samples, _ = librosa.core.load(unclean_file, sr=None)\n",
    "    \n",
    "    trim_diff = clean_samples - unclean_samples\n",
    "    label = archive.read_label(key)\n",
    "    \n",
    "    trimbot = ClipBot(clean_samples, rate).first_word(label)\n",
    "    diffbot = ClipBot(trim_diff, rate).first_word(label)\n",
    "    clipbot = ClipBot(unclean_samples, rate).first_word(label)\n",
    "    \n",
    "    trimbot.draw.audio()\n",
    "    \n",
    "    clipbot.draw.figure()\n",
    "    clipbot.draw.samples()\n",
    "    clipbot.draw.show()\n",
    "\n",
    "    \n",
    "    diffbot.draw.figure()\n",
    "    diffbot.draw.samples()\n",
    "    diffbot.draw.show()\n",
    "\n",
    "    \n",
    "# TODO: move ClipDrawBot to DrawBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%d3` not found.\n"
     ]
    }
   ],
   "source": [
    "%load_ext py_d3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script>\n",
       "requirejs.config({\n",
       "    paths: {\n",
       "        d3: \"//cdnjs.cloudflare.com/ajax/libs/d3/5.15.0/d3\"\n",
       "    }\n",
       "});\n",
       "\n",
       "require([\"d3\"], function(d3) {\n",
       "    window.d3 = d3;\n",
       "});\n",
       "</script>\n",
       "<script>\n",
       "_select = d3.select;\n",
       "\n",
       "d3.select0 = function(selection) {\n",
       "    return _select(\"#d3-cell-0\").select(selection);\n",
       "}\n",
       "d3.selectAll0 = function(selection) {\n",
       "    return _select(\"#d3-cell-0\").selectAll(selection);\n",
       "}\n",
       "</script>\n",
       "\n",
       "<g id=\"d3-cell-0\">\n",
       "        \n",
       "# edge cases:\n",
       "# Burnt-Oak-outtakes:s7e13-2111.012246-2112.833525\n",
       "# Burnt-Oak-outtakes:s7e13-2000.182908-2003.228327\n",
       "\n",
       "</g>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%d3\n",
    "\n",
    "# edge cases:\n",
    "# Burnt-Oak-outtakes:s7e13-2111.012246-2112.833525\n",
    "# Burnt-Oak-outtakes:s7e13-2000.182908-2003.228327"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
